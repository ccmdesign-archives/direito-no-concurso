<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8"/>
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/>
    <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
    <title>prose</title>
    <link rel="stylesheet" href="/blu-lagum/css/styles.css">
    <link rel="stylesheet" href="/blu-lagum/vendor/slick.css">
    <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
    <link rel="stylesheet" href="https://use.typekit.net/aou0hyh.css">
  </head>
  
  <body class="">
    <div id="overlay" class="js-overlay"></div>

    <main role="main">

<article class="prose">
  <header>
    <div class="prose__content">
      <h2><span>Direito Administrativo</span></h2>
      <h1><span>Estado, Governo</span><br><span>e Administração Pública</span></h1>
      <h3 class="authors"><span>Professora Lisiane Brito</span></h3>
    </div>
  </header>
  <div class="smartlink-anchor">
    <div class="prose__content">
      
      <section id="abstract">
        <h1>Abstract</h1>

        <p>There are growing discontinuities between the research practices of data science and established tools of research ethics regulation. Some of the core commitments of existing research ethics <span class="smartlink smartlink--footnote smartlink--000">regulations, such as the distinction</span> between research and practice, cannot be cleanly exported from biomedical research to data science research. Such discontinuities have led some data science practitioners and researchers to move toward rejecting ethics regulations outright. These shifts occur at the same time as a proposal for major revisions to the Common Rule—the primary regulation governing human-subjects research in the USA—is under consideration for the first time in decades. We contextualize these revisions in long-running complaints about regulation of social science research and argue data science should be understood as continuous with social sciences in this regard. The proposed regulations are more flexible and scalable to the methods of non-biomedical research, yet problematically largely exclude data science methods from human-subjects regulation, particularly uses of public datasets. The ethical frameworks for Big Data research are highly contested and in flux, and the potential harms of data science research are unpredictable. We examine several contentious cases of research harms in data science, including the 2014 Facebook emotional contagion study and the 2016 use of geographical data techniques to identify the pseudonymous artist Banksy. To address disputes about application of human-subjects research ethics in data science, critical data studies should offer a historically nuanced theory of "data subjectivity" responsive to the epistemic methods, harms and benefits of data science and commerce.</p>
      </section>

      <section id="introduction">
        <h1>Introduction</h1>

        <p>Critical data studies is in its infancy, but it faces a sub- stantial challenge: as the practice of data science surges ahead, we lack a strong and rigorous sense of ethical parameters for scientific research. There are several problems emerging. First, there is a growing divide between established systems of research ethics in more traditional disciplines and the dynamic norms and research methods of Big Data. Big Data research methods exacerbate a long-standing tension between the social sciences and research regulations that are geared to the methods and harms of biomedical research. Second, <span class="smartlink smartlink--video smartlink--001">US research regulations (both the current rules and proposed revisions) exempt projects that make use of already existing, publicly available datasets on the assumption that they pose only minimal risks to the human subjects they document.</span> But this assumption is founded on a misconception. Publicly available data can be put to a wide range of secondary uses, including being combined with other data sets, that can pose serious risks to individuals and communities. This is one of several risks that are being overlooked in the current debates about the ethics of Big Data studies.</p>

        <p>For example, in 2016, a group of researchers pub- lished a study that sought to reveal the identity of British artist Banksy, who has sought to keep his real name out of the public domain (Hauge et al., 2016). They used geographical profiling, a technique of statis- tical inference traditionally used in serial crimes like rape and murder, to hone in to a suspected person. <span class="smartlink smartlink--article smartlink--002">They analyzed the spatial patterns of Banksy’s art- works around London and Bristol, and then tracked a particular individual who had been named by the Daily Mail as likely to be Banksy.</span> They searched the electoral rolls for this person’s former addresses as well as those of his wife, and places where he likely went to school and played football. Then Banksy’s public art- works were mapped against these streets and neighbor- hoods. They investigated no other "suspects" but argue that their findings support those of the Daily Mail. The researchers claim that their approach could be useful for early identification of terrorists, as "terrorists often also engage in low level activities such as vandalism, graffiti, anti-government leaflet distribution, and banner posting" (Hauge et al., 2016: 5).</p>

        <p>There are many questions that could be asked of this study, not least about the correlation between graffiti and terrorism. But for our purposes, we will only focus on the "ethical note" that appeared at the end of the article: "the authors are aware of, and respectful of, the privacy of [subject name removed] and his relatives and have thus only used data in the public domain" (Hauge et al., 2016: 5). This claim is particularly striking, as it is difficult to see how tracking a specific individual (and their family) to such an invasive degree could be con- sidered respectful of their privacy. But there are now so many data sets about individuals in the public domain, that, while relatively innocuous in themselves, become highly identifying when brought together. The Banksy study is not a large-scale data study, but it echoes the argument made by many Big Data researchers that they are absolved of ethical concerns by pointing to the "publicness" of the data they use. By applying specia- lized tools for tracking terrorists, Hauge et al. revealed sensitive patterns of movement over several decades. Though they only delved into public data stores, they exploited everything they could find about an artist’s personal (and creative) life, and cross-referenced it with the details of a private citizen, in order to expose an identity that the artist sought to keep secret.</p>
        
        <p>The researchers who published the Banksy study say they went through review from an independent ethics board, and while we cannot see their determination, it is likely that they were allowed to track their suspected individual because the data was public as that is a common standard across research ethics regulations.3 We argue it is a useful case study of why public data can be incredibly invasive, and potentially harmful.</p>

        <p>Critical data studies has an important role to play in analyzing and clarifying these issues by situating questions of data ethics regulations and norms within a historical and discursive analysis of the core concepts and norms of research ethics in general. By historicizing extant research ethics norms and regula- tions, we are able to see the disjunctions with the epistemic conditions of data sciences as one more site of negotiation and improvement rather than an implac- able conflict.</p>

        <p>Big Data stretches our concepts of ethical research in significant ways (boyd and Crawford, 2012). It moves ethical inquiry away from traditional harms such as physical pain or a shortened lifespan to less tangible concepts such as information privacy impact and data discrimination. It may involve the traditional concept of a human subject as an individual, or it may affect a much wider distributed grouping or classification of people. It fundamentally changes our understanding of research data to be (at least in theory) infinitely connect- able, indefinitely repurposable, continuously updatable and easily removed from the context of collection. By doing so, it forces us to grapple with the ways in which familiar and practical ethical constraints depended upon research data being temporally and contextually con- strained and restricted by technical infrastructures and financial cost. Further, data science methods create an abstract relationship between researchers and subjects, where work is being done at a distant remove from the communities most concerned, and where consent often amounts to an unread terms of service or a vague priv- acy policy. Together, these shifts are hard to quantify and ameliorate (Zwitter, 2014), frustrating the familiar ethical practices outside of biomedical research. So while extant research ethics and regulations are far from a perfect fit for the methods of Big Data, there is real urgency to define what a "human subject" is in Big Data research and critically interrogate what is owed to "data subjects." What lessons might we learn from the history and implementation of human-subjects research protections in order to better address these growing conceptual and structural discontinuities? How have other non-biomedical fields of science con- fronted the question of ethics through a critical lens?</p>

        <p>Part of the difficulty here is that the precursor dis- ciplines of data science—computer science, applied mathematics and statistics—have not historically con- sidered themselves as conducting human-subjects research. Even though statistics do ultimately represent people, research into math, computational capacity and other numeric modes of analysis rarely exhibited the types of human subjects concerns that are baked into research ethics regulations designed to handle the types of harms found in biomedical research. Such regulatory definitions rest on a set of ethical and epistemic Metcalf and Crawford 3 assumptions which are now under contestation due to Big Data methods.</p>

        <p>For example, data analytics techniques rarely appear as a direct "intervention" in the life or body of an individual human being, which is one of the key requirements for research to be regulated in the USA (Department of Health and Human Services, 2009). The action of Big Data analytics happens mostly at a remove from the point of data collection, which is the most plausible analog for an "interven- tion." Instead, it is focused on data sets that likely have a long lifespan and may be continuously updated and re-analyzed. Similarly, the Common Rule assumes that data which is already publicly available cannot cause any further harm to an individual.4 Yet this fails to account for data analytics techniques that can create a composite picture of a person from disparate datasets that may be innocuous on their own but produce deeply personal insights when combined (Crawford and Schultz, 2014). The assumption (codi- fied in law) that individual harm is the only type of risk researchers are required to track and mitigate undercuts the ability to see and account for harms that affect communities or produce "networked harms" (boyd et al., 2014).</p>

        <p>Implicitly, the existing ethics regulations promote a historically situated understanding of "research sub- jectivity" that is clearly eroded by data science. The assumptions about what constitutes an intervention, when and how consent should occur and what types of harms are relevant, all add up to a picture of the human-research subject that is out of step with large- scale data practices. If the familiar human subject is largely invisible or irrelevant to data science, how are we to devise new ethical parameters? Who is the "data subject" in a large-scale data experiment, and what are they owed?</p>

        <p>In this paper, we offer a preliminary examination of how critical data studies might generate a theory of data subjectivity that would enable responsible scien- tific practice with Big Data methods. We map the dis- continuities between research regulations and data science, focusing in particular on human-subjects pro- tections and the 30 year debate in the USA about the regulation of human-sciences research. We show that while the proposed revisions to the Common Rule are helpful in terms of making research ethics regulations more flexible and scalable to different research methods and types of risk, they problematically exclude data science wholesale in situations that still present serious risks. These exclusions are based on question- able assumptions about publicly available data, researcher–subject relationships and the very nature of "intervention" into the daily lives of those whose data is held within research databases.</p>
      </section>

    </div>
    <aside class="smartlink-wrapper">
      <ol class="footnotes">
        <li class="smartlink-content smartlink-content--000">
          <p>We will focus largely on the US context for the purpose of this paper. Although the specifics of the regulations differ in other nations, the <a href="#">practical and philosophical challenges</a> posed by regulating Big Data with existing norms are similar elsewhere.</p>
        </li>
        <li class="smartlink-content smartlink-content--video smartlink-content--001">
          <iframe src="https://www.youtube.com/embed/lSCgba5XJFY" frameborder="0" allowfullscreen></iframe>
          <p>Lorem ipsum dolor sit amet, consectetur adipisicing elit. Libero, architecto, vero.</p>
        </li>
        <li class="smartlink-content smartlink-content--article smartlink-content--002">
          <h1><a href="#">Where are human subjects in Big Data research? The emerging ethics divide</a></h1>
          <h3>Jacob Metcalf and Kate Crawford</h3>
          <p>There are growing discontinuities between the research practices of data science and established tools of research ethics regulation. Some of the core commitments of existing research ethics regulations, such as the distinction between research and practice, cannot be cleanly exported from biomedical research to data science research. Such discontinuities have led some data science practitioners and researchers to move toward rejecting ethics regulations outright...</p>

        </li>
      </ol>
    </aside>
  </div>  
  
</article>



    
    <script src="/blu-lagum/vendor/jquery-2.1.4.min.js"></script>
    <script src="/blu-lagum/js/scripts.js"></script>

  </body>
</html>